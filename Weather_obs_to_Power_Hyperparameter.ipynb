{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545650a0-59ec-4f2a-b728-344f5a8f7656",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#這兩行讓 matplotlib 的圖可以顯示中文，同時正常顯示負號\n",
    "matplotlib.rc('font', family='Microsoft JhengHei')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import logging\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# 設置Optuna日誌級別為 WARNING，僅顯示警告及以上級別的信息\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9a62ad-78f6-47e4-ad7f-f26b65642f74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06296b5-a641-4066-b815-ad7cb3b01222",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Pytorch_models.metrics import Array_Metrics\n",
    "from Pytorch_models import models as pytorch_models\n",
    "from Pytorch_models import api\n",
    "MAE = Array_Metrics.mae\n",
    "R2_score = Array_Metrics.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716012c6-8b2a-4bda-8d24-9f541d00a19a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.prepare_data import prepare_data\n",
    "from utils.sun_light import calculate_daytime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3032c-a361-4222-9182-dd407b0c23da",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82f0885-2677-4d5a-b119-a36326a9a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2023-08-01'\n",
    "end_date = '2025-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c71cbb-9dc1-403b-9048-431030c67aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_path = './historical/data/'\n",
    "#train_model_path = './trained_model_parameters/model_B_with_one_month_delay/'\n",
    "train_model_path = './trained_model_parameters/model_meta_2024-09-03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45c6998-2054-480a-913c-5d3c3cb1fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_done = {\n",
    "    '風力': False,\n",
    "    '太陽能': False,\n",
    "    '尖峰負載': False,\n",
    "    '夜尖峰': False,\n",
    "}\n",
    "\n",
    "weights_determined = {\n",
    "    '風力': False,\n",
    "    '太陽能': False,\n",
    "    '尖峰負載': False,\n",
    "    '夜尖峰': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "037b3b60-1aa3-47e6-ab1e-2b916ed34605",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['日期', '尖峰負載', '核能', '燃煤', '汽電共生', '燃氣', '燃油', '水力', '風力', '太陽能',\n",
      "       '氣溫_臺北', '最高氣溫_臺北', '最低氣溫_臺北', '風速_臺北', '全天空日射量_臺北', '總雲量_臺北', '東西風_臺北',\n",
      "       '南北風_臺北', '氣溫_高雄', '最高氣溫_高雄', '最低氣溫_高雄', '風速_高雄', '全天空日射量_高雄', '總雲量_高雄',\n",
      "       '東西風_高雄', '南北風_高雄', '氣溫_嘉義', '最高氣溫_嘉義', '最低氣溫_嘉義', '風速_嘉義', '全天空日射量_嘉義',\n",
      "       '總雲量_嘉義', '東西風_嘉義', '南北風_嘉義', '氣溫_東吉島', '最高氣溫_東吉島', '最低氣溫_東吉島',\n",
      "       '風速_東吉島', '全天空日射量_東吉島', '總雲量_東吉島', '東西風_東吉島', '南北風_東吉島', '氣溫_臺中電廠',\n",
      "       '最高氣溫_臺中電廠', '最低氣溫_臺中電廠', '風速_臺中電廠', '東西風_臺中電廠', '南北風_臺中電廠', '日期數字',\n",
      "       '假日', '週六', '週日', '補班', '1~3月', '11~12月', '白日長度', '夜尖峰'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>尖峰負載</th>\n",
       "      <th>核能</th>\n",
       "      <th>燃煤</th>\n",
       "      <th>汽電共生</th>\n",
       "      <th>燃氣</th>\n",
       "      <th>燃油</th>\n",
       "      <th>水力</th>\n",
       "      <th>風力</th>\n",
       "      <th>太陽能</th>\n",
       "      <th>...</th>\n",
       "      <th>南北風_臺中電廠</th>\n",
       "      <th>日期數字</th>\n",
       "      <th>假日</th>\n",
       "      <th>週六</th>\n",
       "      <th>週日</th>\n",
       "      <th>補班</th>\n",
       "      <th>1~3月</th>\n",
       "      <th>11~12月</th>\n",
       "      <th>白日長度</th>\n",
       "      <th>夜尖峰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>3667.5000</td>\n",
       "      <td>187.70</td>\n",
       "      <td>1105.90</td>\n",
       "      <td>139.60</td>\n",
       "      <td>1454.80</td>\n",
       "      <td>36.70</td>\n",
       "      <td>121.10</td>\n",
       "      <td>89.90</td>\n",
       "      <td>494.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.954423</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>3666.3000</td>\n",
       "      <td>188.30</td>\n",
       "      <td>979.30</td>\n",
       "      <td>146.60</td>\n",
       "      <td>1499.20</td>\n",
       "      <td>92.90</td>\n",
       "      <td>180.00</td>\n",
       "      <td>88.90</td>\n",
       "      <td>462.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.699589</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>3431.3000</td>\n",
       "      <td>189.40</td>\n",
       "      <td>1032.80</td>\n",
       "      <td>143.80</td>\n",
       "      <td>1352.70</td>\n",
       "      <td>37.20</td>\n",
       "      <td>157.60</td>\n",
       "      <td>75.00</td>\n",
       "      <td>412.7000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.854368</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>3695.2000</td>\n",
       "      <td>189.60</td>\n",
       "      <td>1169.10</td>\n",
       "      <td>138.90</td>\n",
       "      <td>1403.30</td>\n",
       "      <td>37.30</td>\n",
       "      <td>117.40</td>\n",
       "      <td>143.60</td>\n",
       "      <td>460.9000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257742</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.116667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>3173.0000</td>\n",
       "      <td>189.90</td>\n",
       "      <td>1223.40</td>\n",
       "      <td>61.60</td>\n",
       "      <td>1337.00</td>\n",
       "      <td>38.60</td>\n",
       "      <td>183.70</td>\n",
       "      <td>111.30</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.898843</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.116667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>3997.0806</td>\n",
       "      <td>93.47</td>\n",
       "      <td>1208.45</td>\n",
       "      <td>176.20</td>\n",
       "      <td>1626.72</td>\n",
       "      <td>65.26</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>5.82</td>\n",
       "      <td>747.8806</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597478</td>\n",
       "      <td>606.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.616667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>3953.5619</td>\n",
       "      <td>93.47</td>\n",
       "      <td>1179.84</td>\n",
       "      <td>165.40</td>\n",
       "      <td>1615.99</td>\n",
       "      <td>60.69</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>8.66</td>\n",
       "      <td>742.5219</td>\n",
       "      <td>...</td>\n",
       "      <td>2.068096</td>\n",
       "      <td>607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>3572.7569</td>\n",
       "      <td>93.35</td>\n",
       "      <td>1071.82</td>\n",
       "      <td>73.08</td>\n",
       "      <td>1393.02</td>\n",
       "      <td>35.33</td>\n",
       "      <td>29.47</td>\n",
       "      <td>20.76</td>\n",
       "      <td>803.9969</td>\n",
       "      <td>...</td>\n",
       "      <td>2.161293</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.583333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>3372.6600</td>\n",
       "      <td>93.24</td>\n",
       "      <td>1130.09</td>\n",
       "      <td>82.33</td>\n",
       "      <td>1725.32</td>\n",
       "      <td>37.61</td>\n",
       "      <td>355.48</td>\n",
       "      <td>0.95</td>\n",
       "      <td>730.9367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597478</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2024-09-02</td>\n",
       "      <td>3989.6614</td>\n",
       "      <td>93.35</td>\n",
       "      <td>1162.55</td>\n",
       "      <td>165.03</td>\n",
       "      <td>1689.91</td>\n",
       "      <td>60.43</td>\n",
       "      <td>85.37</td>\n",
       "      <td>30.96</td>\n",
       "      <td>671.3114</td>\n",
       "      <td>...</td>\n",
       "      <td>1.785416</td>\n",
       "      <td>610.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            日期       尖峰負載      核能       燃煤    汽電共生       燃氣     燃油      水力  \\\n",
       "0   2023-08-01  3667.5000  187.70  1105.90  139.60  1454.80  36.70  121.10   \n",
       "1   2023-08-02  3666.3000  188.30   979.30  146.60  1499.20  92.90  180.00   \n",
       "2   2023-08-03  3431.3000  189.40  1032.80  143.80  1352.70  37.20  157.60   \n",
       "3   2023-08-04  3695.2000  189.60  1169.10  138.90  1403.30  37.30  117.40   \n",
       "4   2023-08-05  3173.0000  189.90  1223.40   61.60  1337.00  38.60  183.70   \n",
       "..         ...        ...     ...      ...     ...      ...    ...     ...   \n",
       "386 2024-08-29  3997.0806   93.47  1208.45  176.20  1626.72  65.26  -10.90   \n",
       "387 2024-08-30  3953.5619   93.47  1179.84  165.40  1615.99  60.69   -1.91   \n",
       "388 2024-08-31  3572.7569   93.35  1071.82   73.08  1393.02  35.33   29.47   \n",
       "389 2024-09-01  3372.6600   93.24  1130.09   82.33  1725.32  37.61  355.48   \n",
       "390 2024-09-02  3989.6614   93.35  1162.55  165.03  1689.91  60.43   85.37   \n",
       "\n",
       "         風力       太陽能  ...  南北風_臺中電廠   日期數字  假日  週六  週日  補班  1~3月  11~12月  \\\n",
       "0     89.90  494.8000  ...  2.954423  212.0   0   0   0   0     0       0   \n",
       "1     88.90  462.1000  ...  2.699589  213.0   0   0   0   0     0       0   \n",
       "2     75.00  412.7000  ...  1.854368  214.0   0   0   0   0     0       0   \n",
       "3    143.60  460.9000  ...  2.257742  215.0   0   0   0   0     0       0   \n",
       "4    111.30    0.0000  ...  1.898843  216.0   0   1   0   0     0       0   \n",
       "..      ...       ...  ...       ...    ...  ..  ..  ..  ..   ...     ...   \n",
       "386    5.82  747.8806  ...  1.597478  606.0   0   0   0   0     0       0   \n",
       "387    8.66  742.5219  ...  2.068096  607.0   0   0   0   0     0       0   \n",
       "388   20.76  803.9969  ...  2.161293  608.0   0   1   0   0     0       0   \n",
       "389    0.95  730.9367  ...  1.597478  609.0   0   0   1   0     0       0   \n",
       "390   30.96  671.3114  ...  1.785416  610.0   0   0   0   0     0       0   \n",
       "\n",
       "          白日長度  夜尖峰  \n",
       "0    13.166667    0  \n",
       "1    13.150000    0  \n",
       "2    13.150000    0  \n",
       "3    13.116667    0  \n",
       "4    13.116667    1  \n",
       "..         ...  ...  \n",
       "386  12.616667    0  \n",
       "387  12.600000    0  \n",
       "388  12.583333    0  \n",
       "389  12.550000    0  \n",
       "390  12.533333    0  \n",
       "\n",
       "[391 rows x 57 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_power_df = prepare_data(historical_data_path, start_date=start_date, end_date=end_date)\n",
    "weather_power_df['夜尖峰'] = [0 if se > 20 else 1 for se in weather_power_df['太陽能']]\n",
    "print(weather_power_df.columns)\n",
    "weather_power_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232e5bb-d619-4088-bf3d-cb0240a6c414",
   "metadata": {},
   "source": [
    "# 函數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b333d5e-6ea4-4e61-9def-7c33d43ad73f",
   "metadata": {},
   "source": [
    "## FCN model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da897372-3123-42ff-9403-5e8e08480154",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FCN_model(input_f, output_f, feature_counts, dropout_factor=0, L2_factor=1e-15, mode='regressor'):\n",
    "    if mode == 'regressor':\n",
    "        model = pytorch_models.SimpleNN(input_f, output_f, feature_counts, dropout_factor)\n",
    "    elif mode == 'classifier':\n",
    "        model = pytorch_models.SimpleNN_classifer(input_f, output_f, feature_counts, dropout_factor)\n",
    "    Model_API = api.Model_API(model, L2_factor=L2_factor, classifer=(mode=='classifier'))\n",
    "    return Model_API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf05e9e-85e0-46cd-bb31-cb8f79e5e83a",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf048c6b-87f8-46b0-a087-6b88090c4814",
   "metadata": {},
   "source": [
    "這部分的函數有：  \n",
    "1. get_XY: 從 DataFrame 中提取需要的 X 與 Y 兩個 numpy array。\n",
    "2. five_fold_test: 執行一次 5-fold 測試，會呼叫 get_XY_from_forecast_and_observation。\n",
    "3. hyperparameter_tuning: 針對特定的模型與超參數組合，呼叫 five_fold_test 執行多次 5-fold 測試，並回傳 R2 值。\n",
    "4. optuna_operation: 利用第三方套件 optuna 執行超參數調整，會呼叫 hyperparameter_tuning。\n",
    "\n",
    "流程控制函數 flow_control 會呼叫 optuna_operation，而主程式只會直接呼叫 flow_control。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dea5ed-740d-49d8-b418-6c22ec5ee052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(data_df, Y_feature, X_features=None):\n",
    "    date_related_cols = ['日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月', '白日長度']\n",
    "    \n",
    "    if Y_feature in ['最高氣溫', '最低氣溫', '氣溫', '風速', '日照率', '全天空日射量']:\n",
    "        target = 'obs'\n",
    "    elif Y_feature in ['風力', '太陽能', '尖峰負載', '夜尖峰']:\n",
    "        target = 'pwd'\n",
    "\n",
    "    X_cols = []\n",
    "    if X_features is None:\n",
    "        for this_col in data_df.columns:\n",
    "            if '_' in this_col:\n",
    "                X_cols.append(this_col)\n",
    "        if target == 'pwd':\n",
    "            X_cols += date_related_cols\n",
    "    else:\n",
    "        for col in data_df.columns:\n",
    "            dash_splited = col.split('_')\n",
    "            if len(dash_splited) >= 2:\n",
    "                if dash_splited[0] in X_features:\n",
    "                    X_cols.append(col)\n",
    "            else:\n",
    "                if col in date_related_cols and col in X_features:\n",
    "                    X_cols.append(col)\n",
    "\n",
    "    Xs = np.array(data_df[X_cols])\n",
    "    Ys = np.array(data_df[Y_feature])\n",
    "\n",
    "    return Xs, Ys, X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696ccff-cc3c-44b7-8131-45957f85d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_fold_test(Xs, Ys, model=XGBRegressor(), mode='regressor',\n",
    "                   deep_learning=False, fold_n=5, standard_scale=True, always_test_last_chunk=False):\n",
    "    \n",
    "    def metric(Y_test, Y_pred, mode=mode):\n",
    "        if mode == 'regressor':\n",
    "            return 1 - np.mean((Y_test - Y_pred)**2) / np.var(Y_test)\n",
    "        elif mode == 'classifier':\n",
    "            return f1_score(Y_test, Y_pred)\n",
    "\n",
    "    shuffle = not always_test_last_chunk\n",
    "    kf = KFold(n_splits=fold_n, shuffle=shuffle)\n",
    "    \n",
    "    XY_folds = {}\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(Xs)):\n",
    "        XY_folds[i] = (train_index, test_index)\n",
    "    \n",
    "    metric_test_list = []\n",
    "    metric_train_list = []\n",
    "\n",
    "    if always_test_last_chunk:\n",
    "        iters = [fold_n-1]\n",
    "    else:\n",
    "        iters = range(fold_n)\n",
    "    \n",
    "    for i in iters:\n",
    "        if deep_learning:\n",
    "            input_f = model.model.params['input_f']\n",
    "            output_f = model.model.params['output_f']\n",
    "            feature_counts = model.model.params['feature_counts']\n",
    "            dropout_factor = model.model.params['dropout_factor']\n",
    "            L2_factor = model.L2_factor\n",
    "            model = FCN_model(input_f=input_f, output_f=output_f, feature_counts=feature_counts,\n",
    "                              dropout_factor=dropout_factor, L2_factor=L2_factor,mode=mode)\n",
    "            \n",
    "        X_train = Xs[XY_folds[i][0]]\n",
    "        X_test = Xs[XY_folds[i][1]]\n",
    "        Y_train = Ys[XY_folds[i][0]]\n",
    "        Y_test = Ys[XY_folds[i][1]]\n",
    "\n",
    "        if deep_learning:\n",
    "            X_train_DL, X_val, Y_train_DL, Y_val = train_test_split(X_train, Y_train, test_size=0.20)\n",
    "    \n",
    "        if standard_scale:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            if deep_learning:\n",
    "                X_val = scaler.transform(X_val)\n",
    "            \n",
    "        if deep_learning:\n",
    "            _ = model.fit(X_train_DL, Y_train_DL, X_val, Y_val)\n",
    "        else:\n",
    "            _ = model.fit(X_train, Y_train)\n",
    "    \n",
    "        Y_pred = model.predict(X_test)\n",
    "        metric_test_list.append(metric(Y_test, Y_pred))\n",
    "\n",
    "        Y_pred = model.predict(X_train)\n",
    "        metric_train_list.append(metric(Y_train, Y_pred))\n",
    "\n",
    "    metric_test = np.mean(metric_test_list)\n",
    "    metric_train = np.mean(metric_train_list)\n",
    "    return metric_test, metric_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e588418-3d74-4e43-a187-2779deb9ac5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(trial, Xs, Ys, model_label='RandomForest', n_iters=50, always_test_last_chunk=False):\n",
    "    deep_learning = False\n",
    "    standard_scale = True\n",
    "    if model_label in ['RandomForest', 'XGBoost', 'LightGBM']:\n",
    "        cfg = {'max_depth': trial.suggest_int('max_depth', 2, 15),\n",
    "               'n_estimators': trial.suggest_int('n_estimators', 10, 200)}\n",
    "        max_depth = cfg['max_depth']\n",
    "        n_estimators = cfg['n_estimators']\n",
    "    \n",
    "        if model_label == 'RandomForest':\n",
    "            model = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators)\n",
    "        elif model_label == 'XGBoost':\n",
    "            model = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators)\n",
    "        elif model_label == 'LightGBM':\n",
    "            model = LGBMRegressor(force_col_wise=True, verbose=-1, max_depth=max_depth, n_estimators=n_estimators)\n",
    "    elif model_label == 'SVR':\n",
    "        cfg = {'C': trial.suggest_float('C', 1e-3, 2e2, log=True),\n",
    "               'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])}\n",
    "        C = cfg['C']\n",
    "        kernel = cfg['kernel']\n",
    "        model = SVR(C=C, kernel=kernel)\n",
    "    elif model_label == 'NuSVR':\n",
    "        cfg = {'C': trial.suggest_float('C', 1e-3, 2e2, log=True),\n",
    "               'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "               'nu': trial.suggest_float('nu', 0.1, 0.9)}\n",
    "        C = cfg['C']\n",
    "        kernel = cfg['kernel']\n",
    "        nu = cfg['nu']\n",
    "        model = NuSVR(C=C, kernel=kernel, nu=nu)\n",
    "    elif model_label == 'FCN':\n",
    "        deep_learning = True\n",
    "        standard_scale = False\n",
    "        cfg = {'L2_factor': trial.suggest_float('L2_factor', 1e-3, 1, log=True),\n",
    "               'dropout_factor': trial.suggest_float('dropout_factor', 0, 0.5)}\n",
    "        L2_factor = cfg['L2_factor']\n",
    "        dropout_factor = cfg['dropout_factor']\n",
    "        input_f = Xs.shape[1] \n",
    "        output_f = 1 \n",
    "        feature_counts = [16, 16, 16, 8]\n",
    "        model = FCN_model(input_f=input_f, output_f=output_f, feature_counts=feature_counts,\n",
    "                          dropout_factor=dropout_factor, L2_factor=L2_factor)\n",
    "    elif model_label == 'LinearRegression':\n",
    "        model = LinearRegression()\n",
    "        \n",
    "    R2_list = []\n",
    "    iterator = range(n_iters)\n",
    "    for i in iterator:\n",
    "        R2, _ = five_fold_test(Xs, Ys, model, deep_learning=deep_learning, standard_scale=standard_scale, always_test_last_chunk=always_test_last_chunk)\n",
    "        R2_list.append(R2)\n",
    "\n",
    "    return np.mean(R2_list) - np.std(R2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cca756a-d8ab-4861-9b70-fb69492ee7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_operation(model_xcols, Y_feature, weather_power_df,\n",
    "                     optuna_n_trials=30, n_iters=20, always_test_last_chunk=False, afternoon_peak_only=True):\n",
    "    model_hyperparameters_dict = {}\n",
    "    model_r2_dict = {}\n",
    "    \n",
    "    if always_test_last_chunk:\n",
    "        n_iters = 1\n",
    "\n",
    "    model_labels = list(model_xcols.keys())\n",
    "    \n",
    "    for model_label in model_labels:\n",
    "        X_features = model_xcols[model_label]\n",
    "        Xs, Ys, _ = get_XY(weather_power_df, X_features, Y_feature)\n",
    "\n",
    "        this_n_iters = n_iters\n",
    "        this_optuna_n_trials = optuna_n_trials\n",
    "\n",
    "        if model_label == 'FCN':\n",
    "            this_n_iters = min(this_n_iters, 1)\n",
    "\n",
    "        if model_label == 'LinearRegression':\n",
    "            this_optuna_n_trials = 1\n",
    "            this_n_iters = 1\n",
    "\n",
    "        if afternoon_peak_only and Y_feature=='太陽能':\n",
    "            flag = np.where(Ys>50)[0]\n",
    "            Ys = Ys[flag]\n",
    "            Xs = Xs[flag]\n",
    "\n",
    "        def target_func(trial, model_label=model_label, Xs=Xs, Ys=Ys, n_iters=this_n_iters, always_test_last_chunk=always_test_last_chunk):\n",
    "            return hyperparameter_tuning(trial, model_label=model_label, Xs=Xs, Ys=Ys, n_iters=n_iters, always_test_last_chunk=always_test_last_chunk)\n",
    "        \n",
    "        sampler = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "        with tqdm(total=this_optuna_n_trials) as pbar:\n",
    "            for _ in range(this_optuna_n_trials):\n",
    "                study.optimize(target_func, n_trials=1, catch=(Exception,))\n",
    "                pbar.update(1)\n",
    "        \n",
    "        print(model_label)\n",
    "        for key, v in study.best_params.items():\n",
    "            print(f\"Best {key} = {v}\")\n",
    "        print(f\"Best R2 = {study.best_value}\")\n",
    "    \n",
    "        model_hyperparameters_dict[model_label] = study.best_params\n",
    "        model_r2_dict[model_label] = study.best_value\n",
    "\n",
    "    return model_hyperparameters_dict, model_r2_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1cda19-8035-426c-bb40-8d2031bb2732",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1d90a6b-2768-40b9-a8f9-0348c55c1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlation_matrix(residuals):\n",
    "    N = len(residuals)\n",
    "    matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            matrix[i][j] = np.mean(np.array(residuals[i]) * np.array(residuals[j]))\n",
    "\n",
    "    for i in range(1, N):\n",
    "        for j in range(i):\n",
    "            matrix[i][j] = matrix[j][i]\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "809c00dc-6c35-45c0-8761-0d812ff9182f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sovle_optimal_weights(matrix):\n",
    "    N = matrix.shape[0]\n",
    "    def objective(weights):\n",
    "        return weights.T @ matrix @ weights\n",
    "\n",
    "    initial_weights = np.array([1/N] * N)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1)] * N\n",
    "    result = minimize(objective, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights = result.x\n",
    "    return optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ef44e-3b56-402a-8b2b-719d314f9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_model(model_label, Xs, model_hyperparameters_dict, mode='regressor'):\n",
    "    if mode == 'regressor':\n",
    "        if model_label == 'LinearRegression':\n",
    "            model = LinearRegression()\n",
    "        elif model_label == 'RandomForest':\n",
    "            model = RandomForestRegressor(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'XGBoost':\n",
    "            model = XGBRegressor(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'LightGBM':\n",
    "            model = LGBMRegressor(force_col_wise=True, verbose=-1, **model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'SVR':\n",
    "            model = SVR(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'NuSVR':\n",
    "            model = NuSVR(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'FCN':\n",
    "            input_f = Xs.shape[1]\n",
    "            output_f = 1\n",
    "            feature_counts = [16, 16, 16, 8]\n",
    "            model = FCN_model(input_f=input_f, output_f=output_f, feature_counts=feature_counts,\n",
    "                      **model_hyperparameters_dict[model_label])\n",
    "    elif mode == 'classifier':\n",
    "        if model_label == 'FCN':\n",
    "            input_f = Xs.shape[1]\n",
    "            output_f = 1\n",
    "            feature_counts = [16, 16, 16, 8]\n",
    "            model = FCN_model(input_f=input_f, output_f=output_f, feature_counts=feature_counts,\n",
    "                                mode='classifier', \n",
    "                                **model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'RandomForest':\n",
    "            model = RandomForestClassifier(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'XGBoost':\n",
    "            model = XGBClassifier(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'LightGBM':\n",
    "            model = LGBMClassifier(force_col_wise=True, verbose=-1, **model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'SVC':\n",
    "            model = SVC(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'NuSVC':\n",
    "            model = NuSVC(**model_hyperparameters_dict[model_label])\n",
    "        elif model_label == 'LogisticRegression':\n",
    "            model = LogisticRegression(**model_hyperparameters_dict[model_label])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a7bac67-7169-49ea-98d3-90bdeedcfbc5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_avg_score_with_given_model_list(model_hyperparameters_dict, model_xcols,\n",
    "                                         data_df, Y_feature, mode='regressor',\n",
    "                                         n_iters=200, weights=None):\n",
    "\n",
    "    if mode == 'regressor':\n",
    "        metric_name = 'MAE'\n",
    "    elif mode == 'classifier':\n",
    "        metric_name = 'F1'\n",
    "    \n",
    "    if type(data_df) in [list, tuple]:\n",
    "        if len(data_df) == 2:\n",
    "            forecast_df, observation_df = data_df\n",
    "            target = 'obs'\n",
    "        else:\n",
    "            raise Exception('Input data_df should be a DataFrame or a list contain 2 DataFrames.')\n",
    "    else:\n",
    "        target = 'pwd'\n",
    "    \n",
    "    def get_prediction(model_label, Y_train, train_ind, test_ind,\n",
    "                       model_hyperparameters_dict=model_hyperparameters_dict,\n",
    "                       model_xcols=model_xcols,\n",
    "                       forecast_df=forecast_df,\n",
    "                       observation_df=observation_df, \n",
    "                       Y_feature=Y_feature,\n",
    "                       target=target):\n",
    "        \n",
    "        X_features = model_xcols[model_label]\n",
    "        if target == 'pwd':\n",
    "            Xs, _, _ = get_XY(data_df, Y_feature=Y_feature, X_features=X_features)\n",
    "        elif target == 'obs':\n",
    "            Xs, _, _, _ = get_XY_from_forecast_and_observation(forecast_df, observation_df, X_features, Y_feature)\n",
    "        model = assign_model(model_label, Xs, model_hyperparameters_dict=model_hyperparameters_dict, mode=mode)\n",
    "\n",
    "        deep_learning = False\n",
    "        if model_label == 'FCN':\n",
    "            deep_learning = True\n",
    "    \n",
    "        X_train = Xs[train_ind]\n",
    "        X_test = Xs[test_ind]\n",
    "        \n",
    "        if deep_learning:\n",
    "            X_train_dl, X_val, Y_train_dl, Y_val = train_test_split(X_train, Y_train, test_size=0.20)\n",
    "            _ = model.fit(X_train_dl, Y_train_dl, X_val, Y_val)\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            X_scaler = scaler.fit(X_train)\n",
    "            X_train = X_scaler.transform(X_train)\n",
    "            X_test = X_scaler.transform(X_test)\n",
    "            _ = model.fit(X_train, Y_train)\n",
    "        YP = model.predict(X_test)\n",
    "        return YP        \n",
    "    \n",
    "    if weights is None:\n",
    "        ensemble_models = list(model_hyperparameters_dict.keys())\n",
    "    else:\n",
    "        ensemble_models = list(weights.keys())\n",
    "        \n",
    "    Y_pred_iters = []\n",
    "    Y_test_iters = []\n",
    "    metric = []\n",
    "\n",
    "    X_features=model_xcols[ensemble_models[0]]\n",
    "    if target == 'pwd':\n",
    "        Xs, Ys, _ = get_XY(data_df, Y_feature=Y_feature, X_features=X_features)\n",
    "    elif target == 'obs':\n",
    "        Xs, Ys, _, _ = get_XY_from_forecast_and_observation(forecast_df, observation_df, X_features, Y_feature)\n",
    "\n",
    "    matrix = np.zeros((len(ensemble_models), len(ensemble_models)))\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        train_ind, test_ind, _, _ = train_test_split(np.arange(Xs.shape[0]), np.arange(Xs.shape[0]), test_size=0.20)\n",
    "        \n",
    "        Y_train = Ys[train_ind]\n",
    "        Y_test = Ys[test_ind]\n",
    "        \n",
    "        Y_preds = []\n",
    "        this_metric = []\n",
    "        for model_label in ensemble_models:\n",
    "            YP = get_prediction(model_label, Y_train, train_ind, test_ind)\n",
    "            if mode == 'regressor':\n",
    "                this_metric.append(MAE(Y_test, YP))\n",
    "            elif mode == 'classifier':\n",
    "                YP[np.where(YP<0.5)] = 0\n",
    "                YP[np.where(YP>=0.5)] = 1\n",
    "                this_metric.append(f1_score(Y_test, YP))\n",
    "            Y_preds.append(YP)\n",
    "            \n",
    "        residuals = Y_preds - np.array([Y_test] * len(Y_preds)).reshape(len(Y_preds),-1)\n",
    "        if weights is None:\n",
    "            matrix += cross_correlation_matrix(residuals)\n",
    "\n",
    "        uniform_ensemble_YP = np.mean(Y_preds, axis=0)\n",
    "        if mode == 'regressor':\n",
    "            this_metric.append(MAE(Y_test, uniform_ensemble_YP))\n",
    "        elif mode == 'classifier':\n",
    "            uniform_ensemble_YP[np.where(uniform_ensemble_YP<0.5)] = 0\n",
    "            uniform_ensemble_YP[np.where(uniform_ensemble_YP>=0.5)] = 1\n",
    "            this_metric.append(f1_score(Y_test, uniform_ensemble_YP))\n",
    "\n",
    "        metric.append(this_metric)\n",
    "        Y_pred_iters.append(Y_preds)\n",
    "        Y_test_iters.append(Y_test)\n",
    "\n",
    "    if weights is None:\n",
    "        matrix = matrix / n_iters\n",
    "        optimal_weights = sovle_optimal_weights(matrix)\n",
    "    else:\n",
    "        optimal_weights = weights\n",
    "\n",
    "    weighted_metric = []\n",
    "    for i in range(n_iters):\n",
    "        weighted_YP = np.sum(Y_pred_iters[i] * np.concatenate([optimal_weights.reshape(-1,1),] * Y_test_iters[0].shape[0], axis = 1), axis=0)\n",
    "        if mode == 'regressor':\n",
    "            weighted_metric.append(MAE(Y_test_iters[i], weighted_YP))\n",
    "        elif mode == 'classifier':\n",
    "            weighted_YP[np.where(weighted_YP<0.5)] = 0\n",
    "            weighted_YP[np.where(weighted_YP>=0.5)] = 1\n",
    "            weighted_metric.append(f1_score(Y_test_iters[i], weighted_YP))\n",
    "    weighted_metric = np.array(weighted_metric).reshape(-1, 1)\n",
    "    array_metric = np.array(metric)\n",
    "    array_metric = np.concatenate([metric, weighted_metric], axis=1)\n",
    "    \n",
    "    metric_dict = {\n",
    "        'Model': ensemble_models + ['Ensemble', 'Weighted_Ensemble'],\n",
    "        f'Avg {metric_name}': list(np.mean(array_metric, axis=0)), \n",
    "        f'Std {metric_name}': list(np.std(array_metric, axis=0)),\n",
    "        '90th percentile': list(np.sort(array_metric, axis=0)[int(array_metric.shape[0] * 0.9) - 1]),\n",
    "        '10th percentile': list(np.sort(array_metric, axis=0)[int(array_metric.shape[0] * 0.1) - 1])\n",
    "        }\n",
    "    \n",
    "    df = pd.DataFrame(metric_dict)\n",
    "    if mode == 'regressor':\n",
    "        df = df.sort_values('90th percentile').reset_index(drop=True)\n",
    "    elif mode == 'classifier':\n",
    "        df = df.sort_values('10th percentile').reset_index(drop=True)\n",
    "\n",
    "    if weights is not None:\n",
    "        return df\n",
    "        \n",
    "    optimal_weights_dict = {}\n",
    "    for i, w in enumerate(optimal_weights):\n",
    "        optimal_weights_dict[ensemble_models[i]] = w\n",
    "        \n",
    "    return df, optimal_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbea426-a0d3-4668-a776-2641ea938db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_metadata(file_path, model_xcols, model_hyperparameters_dict, optimal_weights):\n",
    "    model_labels = list(model_hyperparameters_dict)\n",
    "    output_dict = {\n",
    "        'X_feature_dict':{},\n",
    "        'hyperparameters_dict':{},\n",
    "        'weights':{}\n",
    "    }\n",
    "    for model_label in model_labels:\n",
    "        if optimal_weights[model_label] > 0.0005:\n",
    "            output_dict['X_feature_dict'][model_label] = model_xcols[model_label]\n",
    "            output_dict['hyperparameters_dict'][model_label] = model_hyperparameters_dict[model_label]\n",
    "            output_dict['weights'][model_label] = optimal_weights[model_label]\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(output_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952e40e-fc4d-4d17-aa8d-1efaa38b4c45",
   "metadata": {},
   "source": [
    "### 流程控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e42d318a-d3d6-494c-af45-34d2512a6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_control(Y_feature, model_xcols, data_df, speed_test=False, mode='regression',\n",
    "                 train_model_path=train_model_path, optuna_done=optuna_done, weights_determined=weights_determined):\n",
    "\n",
    "    if mode == 'regression':\n",
    "        metric_name = 'MAE'\n",
    "    elif mode == 'classifier':\n",
    "        metric_name = 'F1'\n",
    "    \n",
    "    n_iter_dict = {\n",
    "        'hyper_parameter': 30,\n",
    "        'ensemble_weight': 200\n",
    "    }\n",
    "    if speed_test:\n",
    "        n_iter_dict = {\n",
    "            'hyper_parameter': 1,\n",
    "            'ensemble_weight': 20\n",
    "        }\n",
    "    \n",
    "    this_model_path = f'{train_model_path}{Y_feature}/'\n",
    "    os.makedirs(this_model_path, exist_ok=True)\n",
    "\n",
    "    # 如果指定的 meta 檔存在，並且初始參數規定不須重新計算，則套用存檔數值。\n",
    "    if os.path.exists(f'{train_model_path}{Y_feature}/meta.json'):\n",
    "        with open(f'{train_model_path}{Y_feature}/meta.json', 'r') as f:\n",
    "            meta = json.load(f)\n",
    "    else:\n",
    "        optuna_done[Y_feature] = False\n",
    "        weights_determined[Y_feature] = False\n",
    "\n",
    "    # 超參數\n",
    "    if optuna_done[Y_feature]:\n",
    "        model_xcols = meta['X_feature_dict']\n",
    "        model_hyperparameters_dict = meta['hyperparameters_dict']\n",
    "    else: \n",
    "        model_hyperparameters_dict, model_r2_dict = optuna_operation(model_xcols, Y_feature, data_df, n_iters=n_iter_dict['hyper_parameter'])\n",
    "\n",
    "    # 集成權重\n",
    "    if weights_determined[Y_feature]:\n",
    "        optimal_weights = meta['weights']\n",
    "        df = pd.read_csv(f'{this_model_path}predict_{metric_name}.df')\n",
    "        display(df)\n",
    "        print('Weights:')\n",
    "        for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "            print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "    else:\n",
    "        if 'FCN' in model_hyperparameters_dict.keys():\n",
    "            n_iters = int(n_iter_dict['ensemble_weight']/4)\n",
    "        else:\n",
    "            n_iters = n_iter_dict['ensemble_weight']\n",
    "        df, optimal_weights = find_avg_score_with_given_model_list(model_hyperparameters_dict, model_xcols, data_df, Y_feature, n_iters=n_iters)\n",
    "        display(df)\n",
    "        df.to_csv(f'{this_model_path}predict_{metric_name}.df', index=False, encoding='utf-8-sig')\n",
    "        print('Weights:')\n",
    "        for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "            print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('**Copy and Paste following lines into the next cell.**')\n",
    "    for model_label in model_hyperparameters_dict.keys():\n",
    "        print('##### ' + model_label)\n",
    "        for key, v in model_hyperparameters_dict[model_label].items():\n",
    "            print(f\"Best {key} = {v}  \")\n",
    "        if 'model_r2_dict' in locals().keys():\n",
    "            print(f\"Best R2 = {model_r2_dict[model_label]}  \")\n",
    "        print(f'Weight = {optimal_weights[model_label]:.3f}')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    save_model_metadata(Y_feature, this_model_path + 'meta.json', model_xcols, model_hyperparameters_dict, optimal_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4947f88-27a1-4f7f-bfc8-6c63038d078c",
   "metadata": {},
   "source": [
    "# 風力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd564e-6b37-4ad0-8868-c14ce90addd1",
   "metadata": {},
   "source": [
    "## 超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39413654-6e87-44ca-b5d0-23553072ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Best R2 = 0.6280852942234002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [38:06<00:00, 76.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN\n",
      "Best L2_factor = 0.013005685305042187\n",
      "Best dropout_factor = 0.3959026641543964\n",
      "Best R2 = 0.7200460389841302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [12:34<00:00, 25.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Best max_depth = 10\n",
      "Best n_estimators = 71\n",
      "Best R2 = 0.737423921427763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [04:36<00:00,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Best max_depth = 2\n",
      "Best n_estimators = 76\n",
      "Best R2 = 0.72186083780968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [03:41<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Best max_depth = 13\n",
      "Best n_estimators = 76\n",
      "Best R2 = 0.7303359820446095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "Best C = 151.36176482779152\n",
      "Best kernel = rbf\n",
      "Best R2 = 0.7489775421486635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:29<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVR\n",
      "Best C = 6.627594643188466\n",
      "Best kernel = linear\n",
      "Best nu = 0.30521882998925987\n",
      "Best R2 = 0.6464490390568155\n",
      "##### LinearRegression\n",
      "Best R2 = 0.6280852942234002  \n",
      "##### FCN\n",
      "Best L2_factor = 0.013005685305042187  \n",
      "Best dropout_factor = 0.3959026641543964  \n",
      "Best R2 = 0.7200460389841302  \n",
      "##### RandomForest\n",
      "Best max_depth = 10  \n",
      "Best n_estimators = 71  \n",
      "Best R2 = 0.737423921427763  \n",
      "##### XGBoost\n",
      "Best max_depth = 2  \n",
      "Best n_estimators = 76  \n",
      "Best R2 = 0.72186083780968  \n",
      "##### LightGBM\n",
      "Best max_depth = 13  \n",
      "Best n_estimators = 76  \n",
      "Best R2 = 0.7303359820446095  \n",
      "##### SVR\n",
      "Best C = 151.36176482779152  \n",
      "Best kernel = rbf  \n",
      "Best R2 = 0.7489775421486635  \n",
      "##### NuSVR\n",
      "Best C = 6.627594643188466  \n",
      "Best kernel = linear  \n",
      "Best nu = 0.30521882998925987  \n",
      "Best R2 = 0.6464490390568155  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y_feature = '風力'\n",
    "\n",
    "model_xcols = {\n",
    "    'LinearRegression': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'FCN': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'RandomForest': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'XGBoost': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'LightGBM': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'SVR': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'NuSVR': ['風速', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "}\n",
    "\n",
    "if not optuna_done[Y_feature]:\n",
    "    model_hyperparameters_dict = optuna_operation(model_xcols, Y_feature, weather_power_df)\n",
    "else:\n",
    "    model_hyperparameters_dict = {\n",
    "        'LinearRegression': {},\n",
    "        'FCN': {'L2_factor':0.013006, 'dropout_factor':0.39590},\n",
    "        'RandomForest': {'max_depth': 10, 'n_estimators': 71},\n",
    "        'XGBoost': {'max_depth': 2, 'n_estimators': 76},\n",
    "        'LightGBM': {'max_depth': 13, 'n_estimators': 76},\n",
    "        'SVR': {'C': 151.362, 'kernel': 'rbf'},\n",
    "        'NuSVR': {'C': 6.6276, 'kernel': 'linear', 'nu': 0.3052}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e14cf6d-e49d-4275-ab41-4b2f91785d72",
   "metadata": {},
   "source": [
    "##### LinearRegression\n",
    "Best R2 = 0.6280852942234002  \n",
    "##### FCN\n",
    "Best L2_factor = 0.013005685305042187  \n",
    "Best dropout_factor = 0.3959026641543964  \n",
    "Best R2 = 0.7200460389841302  \n",
    "##### RandomForest\n",
    "Best max_depth = 10  \n",
    "Best n_estimators = 71  \n",
    "Best R2 = 0.737423921427763  \n",
    "##### XGBoost\n",
    "Best max_depth = 2  \n",
    "Best n_estimators = 76  \n",
    "Best R2 = 0.72186083780968  \n",
    "##### LightGBM\n",
    "Best max_depth = 13  \n",
    "Best n_estimators = 76  \n",
    "Best R2 = 0.7303359820446095  \n",
    "##### SVR\n",
    "Best C = 151.36176482779152  \n",
    "Best kernel = rbf  \n",
    "Best R2 = 0.7489775421486635  \n",
    "##### NuSVR\n",
    "Best C = 6.627594643188466  \n",
    "Best kernel = linear  \n",
    "Best nu = 0.30521882998925987  \n",
    "Best R2 = 0.6464490390568155   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f82aa8-e3ea-45ab-b75c-7731b90475ee",
   "metadata": {},
   "source": [
    "## 集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dff1d14-1417-4168-a885-7abaf2167bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [15:18<00:00, 18.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MAE</th>\n",
       "      <th>Std MAE</th>\n",
       "      <th>90th percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weighted_Ensemble</td>\n",
       "      <td>24.199624</td>\n",
       "      <td>2.085586</td>\n",
       "      <td>27.014720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>24.934541</td>\n",
       "      <td>2.325935</td>\n",
       "      <td>27.778277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>25.360287</td>\n",
       "      <td>2.289458</td>\n",
       "      <td>28.179406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>25.745485</td>\n",
       "      <td>2.381327</td>\n",
       "      <td>28.412140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR</td>\n",
       "      <td>26.475461</td>\n",
       "      <td>2.236221</td>\n",
       "      <td>28.824463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>25.858541</td>\n",
       "      <td>2.249777</td>\n",
       "      <td>29.041296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FCN</td>\n",
       "      <td>28.323991</td>\n",
       "      <td>2.764928</td>\n",
       "      <td>32.447912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>33.064959</td>\n",
       "      <td>2.697455</td>\n",
       "      <td>37.106278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>34.024622</td>\n",
       "      <td>2.593434</td>\n",
       "      <td>37.299503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Avg MAE   Std MAE  90th percentile\n",
       "0  Weighted_Ensemble  24.199624  2.085586        27.014720\n",
       "1            XGBoost  24.934541  2.325935        27.778277\n",
       "2           LightGBM  25.360287  2.289458        28.179406\n",
       "3       RandomForest  25.745485  2.381327        28.412140\n",
       "4                SVR  26.475461  2.236221        28.824463\n",
       "5           Ensemble  25.858541  2.249777        29.041296\n",
       "6                FCN  28.323991  2.764928        32.447912\n",
       "7   LinearRegression  33.064959  2.697455        37.106278\n",
       "8              NuSVR  34.024622  2.593434        37.299503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "LinearRegression: 0.000\n",
      "FCN: 0.122\n",
      "RandomForest: 0.023\n",
      "XGBoost: 0.410\n",
      "LightGBM: 0.130\n",
      "SVR: 0.300\n",
      "NuSVR: 0.015\n"
     ]
    }
   ],
   "source": [
    "if weights_determined[Y_feature]:\n",
    "    optimal_weights = {\n",
    "        'LinearRegression': 0.000,\n",
    "        'FCN': 0.122,\n",
    "        'RandomForest': 0.023,\n",
    "        'XGBoost': 0.410,\n",
    "        'LightGBM': 0.130,\n",
    "        'SVR': 0.300,\n",
    "        'NuSVR': 0.015,\n",
    "    }\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "else:\n",
    "    if 'FCN' in model_hyperparameters_dict.keys():\n",
    "        n_iters = 50\n",
    "    else:\n",
    "        n_iters = 200\n",
    "    df, optimal_weights = find_avg_score_with_given_model_list(model_hyperparameters_dict, model_xcols, weather_power_df, Y_feature, n_iters=n_iters)\n",
    "    display(df)\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "\n",
    "this_model_path = train_model_path + f'{Y_feature}/'\n",
    "os.makedirs(this_model_path, exist_ok=True)\n",
    "\n",
    "save_model_metadata(Y_feature, this_model_path + 'meta.json', model_xcols, model_hyperparameters_dict, optimal_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ceca90-7828-441c-9838-878e844d9c8f",
   "metadata": {},
   "source": [
    "# 太陽能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d8592-955e-4334-99a8-d1b297bc9e5a",
   "metadata": {},
   "source": [
    "## 超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b4fc79-b8cb-4af2-aa30-a8db39adb059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Best R2 = 0.6875719046272957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [38:30<00:00, 77.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN\n",
      "Best L2_factor = 0.018184979763796686\n",
      "Best dropout_factor = 0.37066766054759914\n",
      "Best R2 = 0.7101254497981448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [10:40<00:00, 21.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Best max_depth = 13\n",
      "Best n_estimators = 63\n",
      "Best R2 = 0.6804339794603214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [04:20<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Best max_depth = 2\n",
      "Best n_estimators = 41\n",
      "Best R2 = 0.6878504561506845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [02:16<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Best max_depth = 7\n",
      "Best n_estimators = 38\n",
      "Best R2 = 0.6549993136006089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:38<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "Best C = 9.259567086481182\n",
      "Best kernel = linear\n",
      "Best R2 = 0.6769261782554706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:03<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVR\n",
      "Best C = 10.228824707487302\n",
      "Best kernel = linear\n",
      "Best nu = 0.4459203293886881\n",
      "Best R2 = 0.6798091490334639\n",
      "##### LinearRegression\n",
      "Best R2 = 0.6875719046272957  \n",
      "##### FCN\n",
      "Best L2_factor = 0.018184979763796686  \n",
      "Best dropout_factor = 0.37066766054759914  \n",
      "Best R2 = 0.7101254497981448  \n",
      "##### RandomForest\n",
      "Best max_depth = 13  \n",
      "Best n_estimators = 63  \n",
      "Best R2 = 0.6804339794603214  \n",
      "##### XGBoost\n",
      "Best max_depth = 2  \n",
      "Best n_estimators = 41  \n",
      "Best R2 = 0.6878504561506845  \n",
      "##### LightGBM\n",
      "Best max_depth = 7  \n",
      "Best n_estimators = 38  \n",
      "Best R2 = 0.6549993136006089  \n",
      "##### SVR\n",
      "Best C = 9.259567086481182  \n",
      "Best kernel = linear  \n",
      "Best R2 = 0.6769261782554706  \n",
      "##### NuSVR\n",
      "Best C = 10.228824707487302  \n",
      "Best kernel = linear  \n",
      "Best nu = 0.4459203293886881  \n",
      "Best R2 = 0.6798091490334639  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y_feature = '太陽能'\n",
    "\n",
    "universal_xcols = ['氣溫', '最高氣溫', '最低氣溫', '全天空日射量', '日期數字', '假日', '週六', '週日', '補班', '白日長度']\n",
    "\n",
    "model_xcols = {\n",
    "    'LinearRegression': universal_xcols,\n",
    "    'FCN': universal_xcols,\n",
    "    'RandomForest': universal_xcols,\n",
    "    'XGBoost': universal_xcols,\n",
    "    'LightGBM': universal_xcols,\n",
    "    'SVR': universal_xcols,\n",
    "    'NuSVR': universal_xcols,\n",
    "}\n",
    "\n",
    "if not optuna_done[Y_feature]:\n",
    "    model_hyperparameters_dict = optuna_operation(model_xcols, Y_feature, weather_power_df, afternoon_peak_only=False)\n",
    "else:\n",
    "    model_hyperparameters_dict = {\n",
    "        'LinearRegression': {},\n",
    "        'FCN': {'L2_factor': 0.10538, 'dropout_factor': 0.33064},\n",
    "        'RandomForest': {'max_depth': 7, 'n_estimators': 86},\n",
    "        'XGBoost': {'max_depth': 2, 'n_estimators': 48},\n",
    "        'LightGBM': {'max_depth': 2, 'n_estimators': 52},\n",
    "        'SVR': {'C': 3.9957, 'kernel': 'linear'},\n",
    "        'NuSVR': {'C': 9.01112, 'kernel': 'linear', 'nu': 0.5692}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c688c-5fc8-4e96-a265-e774550114c8",
   "metadata": {},
   "source": [
    "##### LinearRegression\n",
    "Best R2 = 0.6635612498392781  \n",
    "##### FCN\n",
    "Best L2_factor = 0.1053827379092039  \n",
    "Best dropout_factor = 0.33064438957159265  \n",
    "Best R2 = 0.7176992185797516  \n",
    "##### RandomForest\n",
    "Best max_depth = 7  \n",
    "Best n_estimators = 86  \n",
    "Best R2 = 0.7111976622077838  \n",
    "##### XGBoost\n",
    "Best max_depth = 2  \n",
    "Best n_estimators = 48  \n",
    "Best R2 = 0.6828467775270773  \n",
    "##### LightGBM\n",
    "Best max_depth = 2  \n",
    "Best n_estimators = 52  \n",
    "Best R2 = 0.7244731778954127  \n",
    "##### SVR\n",
    "Best C = 3.9956951625086528  \n",
    "Best kernel = linear  \n",
    "Best R2 = 0.6759829409350249  \n",
    "##### NuSVR\n",
    "Best C = 9.011120964017998  \n",
    "Best kernel = linear  \n",
    "Best nu = 0.5691703607433763  \n",
    "Best R2 = 0.6795263138372115"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba0d08-9b76-401c-b152-f6b783f96c38",
   "metadata": {},
   "source": [
    "## 集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52074282-f539-4ea7-849e-4204aead1479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [13:42<00:00, 16.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MAE</th>\n",
       "      <th>Std MAE</th>\n",
       "      <th>90th percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weighted_Ensemble</td>\n",
       "      <td>95.205535</td>\n",
       "      <td>9.997782</td>\n",
       "      <td>107.064640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>98.248660</td>\n",
       "      <td>9.591001</td>\n",
       "      <td>109.546216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>98.239794</td>\n",
       "      <td>10.756025</td>\n",
       "      <td>110.935188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>104.635877</td>\n",
       "      <td>9.261996</td>\n",
       "      <td>115.623725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>103.563825</td>\n",
       "      <td>10.366533</td>\n",
       "      <td>116.412344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>110.886522</td>\n",
       "      <td>8.780802</td>\n",
       "      <td>123.151892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FCN</td>\n",
       "      <td>102.917325</td>\n",
       "      <td>13.631693</td>\n",
       "      <td>124.791749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>112.423710</td>\n",
       "      <td>9.528354</td>\n",
       "      <td>125.082204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>112.850473</td>\n",
       "      <td>8.976209</td>\n",
       "      <td>125.269122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model     Avg MAE    Std MAE  90th percentile\n",
       "0  Weighted_Ensemble   95.205535   9.997782       107.064640\n",
       "1           Ensemble   98.248660   9.591001       109.546216\n",
       "2       RandomForest   98.239794  10.756025       110.935188\n",
       "3           LightGBM  104.635877   9.261996       115.623725\n",
       "4            XGBoost  103.563825  10.366533       116.412344\n",
       "5              NuSVR  110.886522   8.780802       123.151892\n",
       "6                FCN  102.917325  13.631693       124.791749\n",
       "7   LinearRegression  112.423710   9.528354       125.082204\n",
       "8                SVR  112.850473   8.976209       125.269122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "LinearRegression: 0.199\n",
      "FCN: 0.335\n",
      "RandomForest: 0.181\n",
      "XGBoost: 0.206\n",
      "LightGBM: 0.080\n",
      "SVR: 0.000\n",
      "NuSVR: 0.000\n"
     ]
    }
   ],
   "source": [
    "if weights_determined[Y_feature]:\n",
    "    optimal_weights = {\n",
    "        'LinearRegression': 0.134,\n",
    "        'FCN': 0.365,\n",
    "        'RandomForest': 0.255,\n",
    "        'XGBoost': 0.246,\n",
    "        'LightGBM': 0.000,\n",
    "        'SVR': 0.000,\n",
    "        'NuSVR': 0.000\n",
    "    }\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "else:\n",
    "    if 'FCN' in model_hyperparameters_dict.keys():\n",
    "        n_iters = 50\n",
    "    else:\n",
    "        n_iters = 200\n",
    "    df, optimal_weights = find_avg_score_with_given_model_list(model_hyperparameters_dict, model_xcols, weather_power_df, Y_feature, n_iters=n_iters)\n",
    "    display(df)\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "\n",
    "this_model_path = train_model_path + f'{Y_feature}/'\n",
    "os.makedirs(this_model_path, exist_ok=True)\n",
    "\n",
    "save_model_metadata(Y_feature, this_model_path + 'meta.json', model_xcols, model_hyperparameters_dict, optimal_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5922277-8f94-4c6f-b27c-9d9f34e622cd",
   "metadata": {},
   "source": [
    "# 尖峰負載"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d5bcb-c494-485f-ad0c-4f01fcc3b889",
   "metadata": {},
   "source": [
    "## 超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "181da18d-a6bb-4c7a-b979-d549e32eabb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Best R2 = 0.9084907998139133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [37:35<00:00, 75.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN\n",
      "Best L2_factor = 0.06427546813184054\n",
      "Best dropout_factor = 0.16268006046854297\n",
      "Best R2 = 0.9454512253809562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [12:55<00:00, 25.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Best max_depth = 12\n",
      "Best n_estimators = 84\n",
      "Best R2 = 0.9121767406884245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [05:59<00:00, 11.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Best max_depth = 2\n",
      "Best n_estimators = 87\n",
      "Best R2 = 0.930225265253464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [04:35<00:00,  9.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Best max_depth = 14\n",
      "Best n_estimators = 80\n",
      "Best R2 = 0.8808688778872141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:33<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "Best C = 196.04254877334432\n",
      "Best kernel = rbf\n",
      "Best R2 = 0.9361217780088962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:01<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVR\n",
      "Best C = 25.491055542125657\n",
      "Best kernel = linear\n",
      "Best nu = 0.32464880623200465\n",
      "Best R2 = 0.9037566008510232\n",
      "##### LinearRegression\n",
      "Best R2 = 0.9084907998139133  \n",
      "##### FCN\n",
      "Best L2_factor = 0.06427546813184054  \n",
      "Best dropout_factor = 0.16268006046854297  \n",
      "Best R2 = 0.9454512253809562  \n",
      "##### RandomForest\n",
      "Best max_depth = 12  \n",
      "Best n_estimators = 84  \n",
      "Best R2 = 0.9121767406884245  \n",
      "##### XGBoost\n",
      "Best max_depth = 2  \n",
      "Best n_estimators = 87  \n",
      "Best R2 = 0.930225265253464  \n",
      "##### LightGBM\n",
      "Best max_depth = 14  \n",
      "Best n_estimators = 80  \n",
      "Best R2 = 0.8808688778872141  \n",
      "##### SVR\n",
      "Best C = 196.04254877334432  \n",
      "Best kernel = rbf  \n",
      "Best R2 = 0.9361217780088962  \n",
      "##### NuSVR\n",
      "Best C = 25.491055542125657  \n",
      "Best kernel = linear  \n",
      "Best nu = 0.32464880623200465  \n",
      "Best R2 = 0.9037566008510232  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y_feature = '尖峰負載'\n",
    "\n",
    "model_xcols = {\n",
    "    'LinearRegression': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'FCN': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'RandomForest': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'XGBoost': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'LightGBM': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'SVR': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "    'NuSVR': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '1~3月', '11~12月'],\n",
    "}\n",
    "\n",
    "if not optuna_done[Y_feature]:\n",
    "    model_hyperparameters_dict = optuna_operation(model_xcols, Y_feature, weather_power_df)\n",
    "else:\n",
    "    model_hyperparameters_dict = {\n",
    "        'LinearRegression': {},\n",
    "        'FCN': {'L2_factor': 0.06428, 'dropout_factor': 0.16268},\n",
    "        'RandomForest': {'max_depth': 12, 'n_estimators': 84},\n",
    "        'XGBoost': {'max_depth': 2, 'n_estimators': 87},\n",
    "        'LightGBM': {'max_depth': 14, 'n_estimators': 80},\n",
    "        'SVR': {'C': 196.04, 'kernel': 'rbf'},\n",
    "        'NuSVR': {'C': 25.491, 'kernel': 'linear', 'nu': 0.3246}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecceee6-fd1a-4a72-b90e-ab41efa26773",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "##### LinearRegression\n",
    "Best R2 = 0.9084907998139133  \n",
    "##### FCN\n",
    "Best L2_factor = 0.06427546813184054  \n",
    "Best dropout_factor = 0.16268006046854297  \n",
    "Best R2 = 0.9454512253809562  \n",
    "##### RandomForest\n",
    "Best max_depth = 12  \n",
    "Best n_estimators = 84  \n",
    "Best R2 = 0.9121767406884245  \n",
    "##### XGBoost\n",
    "Best max_depth = 2  \n",
    "Best n_estimators = 87  \n",
    "Best R2 = 0.930225265253464  \n",
    "##### LightGBM\n",
    "Best max_depth = 14  \n",
    "Best n_estimators = 80  \n",
    "Best R2 = 0.8808688778872141  \n",
    "##### SVR\n",
    "Best C = 196.04254877334432  \n",
    "Best kernel = rbf  \n",
    "Best R2 = 0.9361217780088962  \n",
    "##### NuSVR\n",
    "Best C = 25.491055542125657  \n",
    "Best kernel = linear  \n",
    "Best nu = 0.32464880623200465  \n",
    "Best R2 = 0.9037566008510232  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831439f-a0e7-4dec-b60b-af1288b81f0a",
   "metadata": {},
   "source": [
    "## 集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5427792-f3ac-478a-8a36-c340b4179556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [13:11<00:00, 15.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MAE</th>\n",
       "      <th>Std MAE</th>\n",
       "      <th>90th percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weighted_Ensemble</td>\n",
       "      <td>56.467060</td>\n",
       "      <td>5.360927</td>\n",
       "      <td>64.073659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>57.630002</td>\n",
       "      <td>6.102505</td>\n",
       "      <td>64.643932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>67.834988</td>\n",
       "      <td>6.890786</td>\n",
       "      <td>76.767072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FCN</td>\n",
       "      <td>69.571028</td>\n",
       "      <td>9.613673</td>\n",
       "      <td>78.913223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>73.844534</td>\n",
       "      <td>6.641479</td>\n",
       "      <td>82.271831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>77.023023</td>\n",
       "      <td>9.758401</td>\n",
       "      <td>88.121464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>93.276944</td>\n",
       "      <td>10.538114</td>\n",
       "      <td>106.600944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>114.109195</td>\n",
       "      <td>8.703702</td>\n",
       "      <td>124.941865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>117.002100</td>\n",
       "      <td>8.555598</td>\n",
       "      <td>127.197825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model     Avg MAE    Std MAE  90th percentile\n",
       "0  Weighted_Ensemble   56.467060   5.360927        64.073659\n",
       "1                SVR   57.630002   6.102505        64.643932\n",
       "2           Ensemble   67.834988   6.890786        76.767072\n",
       "3                FCN   69.571028   9.613673        78.913223\n",
       "4            XGBoost   73.844534   6.641479        82.271831\n",
       "5       RandomForest   77.023023   9.758401        88.121464\n",
       "6           LightGBM   93.276944  10.538114       106.600944\n",
       "7   LinearRegression  114.109195   8.703702       124.941865\n",
       "8              NuSVR  117.002100   8.555598       127.197825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "LinearRegression: 0.000\n",
      "FCN: 0.273\n",
      "RandomForest: 0.000\n",
      "XGBoost: 0.198\n",
      "LightGBM: 0.065\n",
      "SVR: 0.463\n",
      "NuSVR: 0.000\n"
     ]
    }
   ],
   "source": [
    "if weights_determined[Y_feature]:\n",
    "    optimal_weights = {\n",
    "        'LinearRegression': 0.000,\n",
    "        'FCN': 0.273,\n",
    "        'RandomForest': 0.000,\n",
    "        'XGBoost': 0.198,\n",
    "        'LightGBM': 0.065,\n",
    "        'SVR': 0.463,\n",
    "        'NuSVR': 0.000\n",
    "    }\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "else:\n",
    "    if 'FCN' in model_hyperparameters_dict.keys():\n",
    "        n_iters = 50\n",
    "    else:\n",
    "        n_iters = 200\n",
    "    df, optimal_weights = find_avg_score_with_given_model_list(model_hyperparameters_dict, model_xcols, weather_power_df, Y_feature, n_iters=n_iters)\n",
    "    display(df)\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "\n",
    "this_model_path = train_model_path + f'{Y_feature}/'\n",
    "os.makedirs(this_model_path, exist_ok=True)\n",
    "\n",
    "save_model_metadata(Y_feature, this_model_path + 'meta.json', model_xcols, model_hyperparameters_dict, optimal_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5d319-dabd-4f8f-a374-9101f7b249a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 夜尖峰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be8a53e-6a5b-4c8c-81bb-62cc5f718146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8ff435-f712-438a-b794-8c714efc9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83403e-2519-4147-a27c-4111b5f22b96",
   "metadata": {},
   "source": [
    "## 超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e3ec3a2-74e1-4a3b-a73e-56a324748ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_fold_classify_test(Xs, Ys, model=XGBRegressor(), deep_learning=False, fold_n=5, standard_scale=True, always_test_last_chunk=False):\n",
    "\n",
    "    shuffle = not always_test_last_chunk\n",
    "    kf = KFold(n_splits=fold_n, shuffle=shuffle)\n",
    "    \n",
    "    XY_folds = {}\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(Xs)):\n",
    "        XY_folds[i] = (train_index, test_index)\n",
    "    \n",
    "    f1_test_list = []\n",
    "    f1_train_list = []\n",
    "\n",
    "    if always_test_last_chunk:\n",
    "        iters = [fold_n-1]\n",
    "    else:\n",
    "        iters = range(fold_n)\n",
    "    \n",
    "    for i in iters:\n",
    "        X_train = Xs[XY_folds[i][0]]\n",
    "        X_test = Xs[XY_folds[i][1]]\n",
    "        Y_train = Ys[XY_folds[i][0]]\n",
    "        Y_test = Ys[XY_folds[i][1]]\n",
    "\n",
    "        if deep_learning:\n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.20)\n",
    "    \n",
    "        if standard_scale:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "        if deep_learning:\n",
    "            _ = model.fit(X_train, Y_train, X_val, Y_val)\n",
    "        else:\n",
    "            _ = model.fit(X_train, Y_train)\n",
    "\n",
    "        Y_pred = model.predict(X_test)\n",
    "        # if deep_learning:\n",
    "        #     Y_pred[np.where(Y_pred<0.5)] = 0\n",
    "        #     Y_pred[np.where(Y_pred>=0.5)] = 1\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        f1_test_list.append(f1)   \n",
    "\n",
    "        Y_pred = model.predict(X_train)\n",
    "        # if deep_learning:\n",
    "        #     Y_pred[np.where(Y_pred<0.5)] = 0\n",
    "        #     Y_pred[np.where(Y_pred>=0.5)] = 1\n",
    "        f1 = f1_score(Y_train, Y_pred)\n",
    "        f1_train_list.append(f1)\n",
    "\n",
    "    # if deep_learning:\n",
    "    #     print(R2_train_list, R2_test_list)\n",
    "\n",
    "    f1_test = np.mean(f1_test_list)\n",
    "    f1_train = np.mean(f1_train_list)\n",
    "    return f1_test, f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0928b58e-4889-4aa6-aa3f-ffd791718d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfier_hyperparameter_tuning(trial, Xs, Ys, model_label='RandomForest', n_iters=50, always_test_last_chunk=False):\n",
    "    deep_learning = False\n",
    "    standard_scale = True\n",
    "    if model_label in ['RandomForest', 'XGBoost', 'LightGBM']:\n",
    "        cfg = {'max_depth': trial.suggest_int('max_depth', 2, 15),\n",
    "               'n_estimators': trial.suggest_int('n_estimators', 10, 100)}\n",
    "        max_depth = cfg['max_depth']\n",
    "        n_estimators = cfg['n_estimators']\n",
    "    \n",
    "        if model_label == 'RandomForest':\n",
    "            model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "        elif model_label == 'XGBoost':\n",
    "            model = XGBClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "        elif model_label == 'LightGBM':\n",
    "            model = LGBMClassifier(force_col_wise=True, verbose=-1, max_depth=max_depth, n_estimators=n_estimators)\n",
    "    elif model_label == 'SVC':\n",
    "        cfg = {'C': trial.suggest_float('C', 1e-3, 2e2, log=True),\n",
    "               'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])}\n",
    "        C = cfg['C']\n",
    "        kernel = cfg['kernel']\n",
    "        model = SVC(C=C, kernel=kernel)\n",
    "    elif model_label == 'LogisticRegression':\n",
    "        cfg = {'C': trial.suggest_float('C', 1e-3, 2e2, log=True),\n",
    "               'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'])}\n",
    "        C = cfg['C']\n",
    "        solver = cfg['solver']\n",
    "        model = LogisticRegression(C=C, solver=solver)\n",
    "    elif model_label == 'FCN':\n",
    "        deep_learning = True\n",
    "        standard_scale = False\n",
    "        cfg = {'L2_factor': trial.suggest_float('L2_factor', 1e-3, 1, log=True),\n",
    "               'dropout_factor': trial.suggest_float('dropout_factor', 0, 0.5)}\n",
    "        L2_factor = cfg['L2_factor']\n",
    "        dropout_factor = cfg['dropout_factor']\n",
    "        input_f = Xs.shape[1] \n",
    "        output_f = 1 \n",
    "        feature_counts = [16, 16, 16, 8]\n",
    "        model = FCN_model(input_f=input_f, output_f=output_f, feature_counts=feature_counts,\n",
    "                          dropout_factor=dropout_factor, L2_factor=L2_factor, mode='classifier')\n",
    "\n",
    "    f1_list = []\n",
    "    if deep_learning:\n",
    "        iterator = tqdm(range(n_iters))\n",
    "    else:\n",
    "        iterator = range(n_iters)\n",
    "    for i in iterator:\n",
    "        f1, _ = five_fold_classify_test(Xs, Ys, model, deep_learning=deep_learning, standard_scale=standard_scale, always_test_last_chunk=always_test_last_chunk)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return np.mean(f1_list) - np.std(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "875fe95d-37db-4a03-885a-a94e925e018f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:39<00:00, 55.80s/it]\n",
      "[I 2024-08-23 07:59:49,576] Trial 0 finished with value: 0.9019225096322319 and parameters: {'L2_factor': 0.007954844122301383, 'dropout_factor': 0.12922623333443561}. Best is trial 0 with value: 0.9019225096322319.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:33<00:00, 54.74s/it]\n",
      "[I 2024-08-23 08:04:23,302] Trial 1 finished with value: 0.915618958116226 and parameters: {'L2_factor': 0.007004763414176608, 'dropout_factor': 0.22686705584943279}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:10<00:00, 50.19s/it]\n",
      "[I 2024-08-23 08:08:34,274] Trial 2 finished with value: 0.8892158035110497 and parameters: {'L2_factor': 0.0013742869015804546, 'dropout_factor': 0.3541162880512968}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:07<00:00, 49.42s/it]\n",
      "[I 2024-08-23 08:12:41,364] Trial 3 finished with value: -0.025142857142857144 and parameters: {'L2_factor': 0.16024792382180725, 'dropout_factor': 0.39891422877008814}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:11<00:00, 50.38s/it]\n",
      "[I 2024-08-23 08:16:53,280] Trial 4 finished with value: 0.0 and parameters: {'L2_factor': 0.2107312347808834, 'dropout_factor': 0.47816333308469305}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:26<00:00, 53.36s/it]\n",
      "[I 2024-08-23 08:21:20,076] Trial 5 finished with value: 0.8243681884889935 and parameters: {'L2_factor': 0.13000819662680643, 'dropout_factor': 0.16145101141879165}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:08<00:00, 49.62s/it]\n",
      "[I 2024-08-23 08:25:28,191] Trial 6 finished with value: 0.9081488523827851 and parameters: {'L2_factor': 0.003382988599913625, 'dropout_factor': 0.08501012231727084}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:21<00:00, 52.34s/it]\n",
      "[I 2024-08-23 08:29:49,883] Trial 7 finished with value: -0.04224338624338625 and parameters: {'L2_factor': 0.20968691304773387, 'dropout_factor': 0.1949669021677799}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:11<00:00, 50.24s/it]\n",
      "[I 2024-08-23 08:34:01,084] Trial 8 finished with value: 0.8605311927910783 and parameters: {'L2_factor': 0.014252059991883512, 'dropout_factor': 0.31954624587848746}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:33<00:00, 54.77s/it]\n",
      "[I 2024-08-23 08:38:34,938] Trial 9 finished with value: 0.0 and parameters: {'L2_factor': 0.34199683797072045, 'dropout_factor': 0.1405465554898478}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:07<00:00, 49.42s/it]\n",
      "[I 2024-08-23 08:42:42,039] Trial 10 finished with value: 0.8741230723082923 and parameters: {'L2_factor': 0.042119943718142115, 'dropout_factor': 0.262398802513209}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:05<00:00, 49.06s/it]\n",
      "[I 2024-08-23 08:46:47,356] Trial 11 finished with value: 0.915604732252335 and parameters: {'L2_factor': 0.0022277731873843933, 'dropout_factor': 0.005719667249912755}. Best is trial 1 with value: 0.915618958116226.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:36<00:00, 55.37s/it]\n",
      "[I 2024-08-23 08:51:24,190] Trial 12 finished with value: 0.9181886767959401 and parameters: {'L2_factor': 0.0010878739113053559, 'dropout_factor': 0.0055804268275599835}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:23<00:00, 52.70s/it]\n",
      "[I 2024-08-23 08:55:47,679] Trial 13 finished with value: 0.9119248539964896 and parameters: {'L2_factor': 0.0051883456037890964, 'dropout_factor': 0.01365454425168311}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:03<00:00, 48.69s/it]\n",
      "[I 2024-08-23 08:59:51,142] Trial 14 finished with value: 0.8976884867140202 and parameters: {'L2_factor': 0.0010431427410390226, 'dropout_factor': 0.23728968295361896}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:49<00:00, 45.97s/it]\n",
      "[I 2024-08-23 09:03:41,025] Trial 15 finished with value: 0.9050211866009544 and parameters: {'L2_factor': 0.025112121831933034, 'dropout_factor': 0.07235948638873582}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:53<00:00, 46.70s/it]\n",
      "[I 2024-08-23 09:07:34,545] Trial 16 finished with value: 0.0 and parameters: {'L2_factor': 0.9600105806983903, 'dropout_factor': 0.47409175622357275}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:20<00:00, 52.01s/it]\n",
      "[I 2024-08-23 09:11:54,579] Trial 17 finished with value: 0.8943813700592389 and parameters: {'L2_factor': 0.00805058251071761, 'dropout_factor': 0.28935986834651695}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:52<00:00, 46.46s/it]\n",
      "[I 2024-08-23 09:15:46,882] Trial 18 finished with value: 0.8678400759521208 and parameters: {'L2_factor': 0.044494605954931266, 'dropout_factor': 0.21418099147558306}. Best is trial 12 with value: 0.9181886767959401.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:46<00:00, 45.25s/it]\n",
      "[I 2024-08-23 09:19:33,133] Trial 19 finished with value: 0.9278767798462748 and parameters: {'L2_factor': 0.0024482542233747982, 'dropout_factor': 0.07396419773247531}. Best is trial 19 with value: 0.9278767798462748.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:53<00:00, 46.76s/it]\n",
      "[I 2024-08-23 09:23:26,944] Trial 20 finished with value: 0.9027708903584397 and parameters: {'L2_factor': 0.002381657170375995, 'dropout_factor': 0.06707090272025377}. Best is trial 19 with value: 0.9278767798462748.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:43<00:00, 44.64s/it]\n",
      "[I 2024-08-23 09:27:10,145] Trial 21 finished with value: 0.9351033701188657 and parameters: {'L2_factor': 0.004452629151704427, 'dropout_factor': 0.040723178592473194}. Best is trial 21 with value: 0.9351033701188657.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:44<00:00, 44.84s/it]\n",
      "[I 2024-08-23 09:30:54,347] Trial 22 finished with value: 0.9199944660269701 and parameters: {'L2_factor': 0.001790867003554864, 'dropout_factor': 0.040984352461292325}. Best is trial 21 with value: 0.9351033701188657.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:39<00:00, 43.92s/it]\n",
      "[I 2024-08-23 09:34:33,958] Trial 23 finished with value: 0.9048299202938217 and parameters: {'L2_factor': 0.0035214103181846756, 'dropout_factor': 0.09816093419846944}. Best is trial 21 with value: 0.9351033701188657.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:39<00:00, 43.95s/it]\n",
      "[I 2024-08-23 09:38:13,705] Trial 24 finished with value: 0.9170566417060463 and parameters: {'L2_factor': 0.0020823747704697194, 'dropout_factor': 0.04480713528884472}. Best is trial 21 with value: 0.9351033701188657.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:49<00:00, 45.94s/it]\n",
      "[I 2024-08-23 09:42:03,431] Trial 25 finished with value: 0.8970230426661782 and parameters: {'L2_factor': 0.01851645972851185, 'dropout_factor': 0.12061111793259038}. Best is trial 21 with value: 0.9351033701188657.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:43<00:00, 44.70s/it]\n",
      "[I 2024-08-23 09:45:46,962] Trial 26 finished with value: 0.9357051406546071 and parameters: {'L2_factor': 0.004163987402538657, 'dropout_factor': 0.04681459826313567}. Best is trial 26 with value: 0.9357051406546071.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:40<00:00, 44.06s/it]\n",
      "[I 2024-08-23 09:49:27,293] Trial 27 finished with value: 0.8905268264196203 and parameters: {'L2_factor': 0.013477890114824545, 'dropout_factor': 0.18560744018984313}. Best is trial 26 with value: 0.9357051406546071.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:44<00:00, 44.84s/it]\n",
      "[I 2024-08-23 09:53:11,498] Trial 28 finished with value: 0.899574937461153 and parameters: {'L2_factor': 0.004552565009632227, 'dropout_factor': 0.04905727903079688}. Best is trial 26 with value: 0.9357051406546071.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:45<00:00, 45.14s/it]\n",
      "[I 2024-08-23 09:56:57,210] Trial 29 finished with value: 0.9232354187053053 and parameters: {'L2_factor': 0.008497426484659816, 'dropout_factor': 0.11764592975419894}. Best is trial 26 with value: 0.9357051406546071.\n",
      "[I 2024-08-23 09:56:57,218] A new study created in memory with name: no-name-e44033c3-e04a-4773-b48a-d39f5df946f9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN\n",
      "Best L2_factor = 0.004163987402538657\n",
      "Best dropout_factor = 0.04681459826313567\n",
      "Best F1 = 0.9357051406546071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Best C = 1.734469249164027\n",
      "Best solver = lbfgs\n",
      "Best F1 = 0.8651748530262853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Best max_depth = 12\n",
      "Best n_estimators = 66\n",
      "Best F1 = 0.7867848119055804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:35<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Best max_depth = 13\n",
      "Best n_estimators = 58\n",
      "Best F1 = 0.8620380494806515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:51<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Best max_depth = 4\n",
      "Best n_estimators = 47\n",
      "Best F1 = 0.8034221631560704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:05<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Best C = 0.5998126005686496\n",
      "Best kernel = linear\n",
      "Best F1 = 0.867829947637113\n",
      "##### FCN\n",
      "Best L2_factor = 0.004163987402538657  \n",
      "Best dropout_factor = 0.04681459826313567  \n",
      "Best F1 = 0.9357051406546071  \n",
      "##### LogisticRegression\n",
      "Best C = 1.734469249164027  \n",
      "Best solver = lbfgs  \n",
      "Best F1 = 0.8651748530262853  \n",
      "##### RandomForest\n",
      "Best max_depth = 12  \n",
      "Best n_estimators = 66  \n",
      "Best F1 = 0.7867848119055804  \n",
      "##### XGBoost\n",
      "Best max_depth = 13  \n",
      "Best n_estimators = 58  \n",
      "Best F1 = 0.8620380494806515  \n",
      "##### LightGBM\n",
      "Best max_depth = 4  \n",
      "Best n_estimators = 47  \n",
      "Best F1 = 0.8034221631560704  \n",
      "##### SVC\n",
      "Best C = 0.5998126005686496  \n",
      "Best kernel = linear  \n",
      "Best F1 = 0.867829947637113  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Y_feature = '夜尖峰'\n",
    "model_xcols = {\n",
    "    'FCN': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '白日長度'],\n",
    "    'LogisticRegression': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '白日長度'],\n",
    "    'RandomForest': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '白日長度'],\n",
    "    'XGBoost': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '白日長度'],\n",
    "    'LightGBM': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '白日長度'],\n",
    "    'SVC': ['氣溫', '最高氣溫', '最低氣溫', '日期數字', '假日', '週六', '週日', '補班', '白日長度']\n",
    "}\n",
    "\n",
    "if not optuna_done[Y_feature]:\n",
    "    model_hyperparameters_dict = {}\n",
    "    model_r2_dict = {}\n",
    "    optuna_n_trials = 30\n",
    "    n_iters = 20\n",
    "    always_test_last_chunk = False\n",
    "    if always_test_last_chunk:\n",
    "        n_iters = 1\n",
    "\n",
    "    model_labels = model_xcols.keys()\n",
    "    \n",
    "    for model_label in model_labels:\n",
    "        X_features = model_xcols[model_label]\n",
    "        Xs, Ys, X_cols = get_XY(weather_power_df, Y_feature=Y_feature)\n",
    "        if model_label == 'FCN':\n",
    "            n_iters = min(n_iters, 5)\n",
    "        def target_func(trial, model_label=model_label, Xs=Xs, Ys=Ys, n_iters=n_iters, always_test_last_chunk=always_test_last_chunk):\n",
    "            return classfier_hyperparameter_tuning(trial, model_label=model_label, Xs=Xs, Ys=Ys, n_iters=n_iters, always_test_last_chunk=always_test_last_chunk)\n",
    "        \n",
    "        sampler = optuna.samplers.TPESampler()\n",
    "        study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "\n",
    "        if model_label == 'FCN':\n",
    "            optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "            study.optimize(target_func, n_trials=optuna_n_trials)\n",
    "        else:\n",
    "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "            with tqdm(total=optuna_n_trials) as pbar:\n",
    "                for _ in range(optuna_n_trials):\n",
    "                    study.optimize(target_func, n_trials=1, catch=(Exception,))\n",
    "                    pbar.update(1)\n",
    "    \n",
    "        print(model_label)\n",
    "        for key, v in study.best_params.items():\n",
    "            print(f\"Best {key} = {v}\")\n",
    "        print(f\"Best F1 = {study.best_value}\")\n",
    "    \n",
    "        model_hyperparameters_dict[model_label] = study.best_params\n",
    "        model_r2_dict[model_label] = study.best_value\n",
    "        \n",
    "    for model_label in model_labels:\n",
    "        print('##### ' + model_label)\n",
    "        for key, v in model_hyperparameters_dict[model_label].items():\n",
    "            print(f\"Best {key} = {v}  \")\n",
    "        print(f\"Best F1 = {model_r2_dict[model_label]}  \")\n",
    "else:\n",
    "    model_hyperparameters_dict = {\n",
    "        'FCN': {'L2_factor': 0.004164, 'dropout_factor': 0.04681},\n",
    "        'LogisticRegression': {'C': 1.734, 'solver': 'lbfgs'},\n",
    "        'RandomForest': {'max_depth': 12, 'n_estimators': 66},\n",
    "        'XGBoost': {'max_depth': 13, 'n_estimators': 58},\n",
    "        'LightGBM': {'max_depth': 4, 'n_estimators': 47},\n",
    "        'SVC': {'C': 0.5998, 'kernel': 'linear'}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50354a52-b2ca-41a5-a6f3-5bf2e1804afc",
   "metadata": {},
   "source": [
    "##### FCN\n",
    "Best L2_factor = 0.004163987402538657  \n",
    "Best dropout_factor = 0.04681459826313567  \n",
    "Best F1 = 0.9357051406546071  \n",
    "##### LogisticRegression\n",
    "Best C = 1.734469249164027  \n",
    "Best solver = lbfgs  \n",
    "Best F1 = 0.8651748530262853  \n",
    "##### RandomForest\n",
    "Best max_depth = 12  \n",
    "Best n_estimators = 66  \n",
    "Best F1 = 0.7867848119055804  \n",
    "##### XGBoost\n",
    "Best max_depth = 13  \n",
    "Best n_estimators = 58  \n",
    "Best F1 = 0.8620380494806515  \n",
    "##### LightGBM\n",
    "Best max_depth = 4  \n",
    "Best n_estimators = 47  \n",
    "Best F1 = 0.8034221631560704  \n",
    "##### SVC\n",
    "Best C = 0.5998126005686496  \n",
    "Best kernel = linear  \n",
    "Best F1 = 0.867829947637113 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83823f5-90fb-4089-9ecd-2fe6fdf7e017",
   "metadata": {},
   "source": [
    "## 集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "946e129d-b42c-42d0-9b89-2763d0976394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_classification_weights(model_hyperparameters_dict, model_xcols, data_df, Y_feature, n_iters=200):\n",
    "    ensemble_models = list(model_hyperparameters_dict.keys())\n",
    "    Y_pred_iters = []\n",
    "    Y_test_iters = []\n",
    "    f1s = []\n",
    "\n",
    "    Xs, Ys, X_cols = get_XY(data_df, Y_feature)\n",
    "    n_samples = Xs.shape[0]\n",
    "\n",
    "    matrix = np.zeros((len(ensemble_models), len(ensemble_models)))\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        train_ind, test_ind, _, _ = train_test_split(np.arange(Xs.shape[0]), np.arange(Xs.shape[0]), test_size=0.20)\n",
    "        \n",
    "        Y_train = Ys[train_ind]\n",
    "        Y_test = Ys[test_ind]\n",
    "        \n",
    "        Y_preds = []\n",
    "        this_f1 = []\n",
    "        \n",
    "        for model_label in ensemble_models:\n",
    "            X_features = model_xcols[model_label]\n",
    "            Xs, Ys, X_cols = get_XY(data_df, Y_feature, X_features)\n",
    "            deep_learning = False\n",
    "            if model_label == 'FCN':\n",
    "                input_f = Xs.shape[1]\n",
    "                output_f = 1\n",
    "                feature_counts = [16, 16, 16, 8]\n",
    "                deep_learning = True\n",
    "                model = FCN_model(input_f=input_f, output_f=output_f, feature_counts=feature_counts,\n",
    "                                  mode='classifier', \n",
    "                                  **model_hyperparameters_dict[model_label])\n",
    "            elif model_label == 'RandomForest':\n",
    "                model = RandomForestClassifier(**model_hyperparameters_dict[model_label])\n",
    "            elif model_label == 'XGBoost':\n",
    "                model = XGBClassifier(**model_hyperparameters_dict[model_label])\n",
    "            elif model_label == 'LightGBM':\n",
    "                model = LGBMClassifier(force_col_wise=True, verbose=-1, **model_hyperparameters_dict[model_label])\n",
    "            elif model_label == 'SVC':\n",
    "                model = SVC(**model_hyperparameters_dict[model_label])\n",
    "            elif model_label == 'NuSVC':\n",
    "                model = NuSVC(**model_hyperparameters_dict[model_label])\n",
    "            elif model_label == 'LogisticRegression':\n",
    "                model = LogisticRegression(**model_hyperparameters_dict[model_label])\n",
    "        \n",
    "            X_train = Xs[train_ind]\n",
    "            X_test = Xs[test_ind]\n",
    "\n",
    "            if deep_learning:\n",
    "                X_train_dl, X_val, Y_train_dl, Y_val = train_test_split(X_train, Y_train, test_size=0.20)\n",
    "\n",
    "            \n",
    "            if deep_learning:\n",
    "                scaler = StandardScaler()\n",
    "                X_scaler = scaler.fit(X_train_dl)\n",
    "                X_train_dl = X_scaler.transform(X_train_dl)\n",
    "                X_test = X_scaler.transform(X_test)\n",
    "                X_val = X_scaler.transform(X_val)\n",
    "                _ = model.fit(X_train_dl, Y_train_dl, X_val, Y_val)\n",
    "            else:\n",
    "                scaler = StandardScaler()\n",
    "                X_scaler = scaler.fit(X_train)\n",
    "                X_train = X_scaler.transform(X_train)\n",
    "                X_test = X_scaler.transform(X_test)\n",
    "                _ = model.fit(X_train, Y_train)\n",
    "\n",
    "            YP = model.predict(X_test)\n",
    "            YP[np.where(YP<0.5)] = 0\n",
    "            YP[np.where(YP>=0.5)] = 1\n",
    "            Y_preds.append(YP)\n",
    "            this_f1.append(f1_score(Y_test, YP))\n",
    "\n",
    "        #print(Y_preds)\n",
    "        residuals = Y_preds - np.array([Y_test] * len(Y_preds)).reshape(len(Y_preds),-1)\n",
    "        matrix += cross_correlation_matrix(residuals)\n",
    "\n",
    "        mean_YP = np.mean(Y_preds, axis=0)\n",
    "        mean_YP[np.where(mean_YP<0.5)] = 0\n",
    "        mean_YP[np.where(mean_YP>=0.5)] = 1\n",
    "        this_f1.append(f1_score(Y_test, mean_YP))\n",
    "        f1s.append(this_f1)\n",
    "        Y_pred_iters.append(Y_preds)\n",
    "        Y_test_iters.append(Y_test)\n",
    "\n",
    "    matrix = matrix / n_iters\n",
    "    optimal_weights = sovle_optimal_weights(matrix)\n",
    "\n",
    "    optimal_weights_dict = {}\n",
    "    for i, w in enumerate(optimal_weights):\n",
    "        optimal_weights_dict[ensemble_models[i]] = w\n",
    "\n",
    "    weighted_f1s = []\n",
    "    for i in range(n_iters):\n",
    "        this_pred = np.sum(Y_pred_iters[i] * np.concatenate([optimal_weights.reshape(-1,1),] * Y_test_iters[0].shape[0], axis = 1), axis=0)\n",
    "        this_pred[np.where(this_pred<0.5)] = 0\n",
    "        this_pred[np.where(this_pred>=0.5)] = 1\n",
    "        weighted_f1s.append(f1_score(Y_test_iters[i], this_pred))\n",
    "    weighted_f1s = np.array(weighted_f1s).reshape(-1, 1)\n",
    "    array_f1s = np.array(f1s)\n",
    "    array_f1s = np.concatenate([f1s, weighted_f1s], axis=1)\n",
    "    \n",
    "    f1_dict = {'Model': ensemble_models + ['Ensemble', 'Weighted_Ensemble'],\n",
    "                'Avg F1': list(np.mean(array_f1s, axis=0)), \n",
    "                'Std F1': list(np.std(array_f1s, axis=0)),\n",
    "                '10th percentile': list(np.sort(array_f1s, axis=0)[int(array_f1s.shape[0] * 0.1) - 1])}\n",
    "    df = pd.DataFrame(f1_dict)\n",
    "    df = df.sort_values('10th percentile', ascending=False).reset_index(drop=True)\n",
    "    return df, optimal_weights_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6327d0d-757e-4c58-86b3-4cbf2e9e5a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [12:29<00:00, 14.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg F1</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>10th percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.865519</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted_Ensemble</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.050990</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.855052</td>\n",
       "      <td>0.045831</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.857315</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.856837</td>\n",
       "      <td>0.054064</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.826234</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.056265</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FCN</td>\n",
       "      <td>0.848015</td>\n",
       "      <td>0.066077</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Avg F1    Std F1  10th percentile\n",
       "0            Ensemble  0.865519  0.055901         0.800000\n",
       "1   Weighted_Ensemble  0.858722  0.050990         0.800000\n",
       "2  LogisticRegression  0.855052  0.045831         0.790698\n",
       "3             XGBoost  0.857315  0.057343         0.777778\n",
       "4                 SVC  0.856837  0.054064         0.765957\n",
       "5            LightGBM  0.826234  0.060027         0.756757\n",
       "6        RandomForest  0.832776  0.056265         0.750000\n",
       "7                 FCN  0.848015  0.066077         0.740741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "FCN: 0.257\n",
      "LogisticRegression: 0.140\n",
      "RandomForest: 0.206\n",
      "XGBoost: 0.182\n",
      "LightGBM: 0.085\n",
      "SVC: 0.130\n"
     ]
    }
   ],
   "source": [
    "if weights_determined[Y_feature]:\n",
    "    optimal_weights = {\n",
    "        'FCN': 0.257,\n",
    "        'LogisticRegression': 0.140,\n",
    "        'RandomForest': 0.206,\n",
    "        'XGBoost': 0.182,\n",
    "        'LightGBM': 0.085,\n",
    "        'SVC': 0.130\n",
    "    }\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "else:\n",
    "    if 'FCN' in model_hyperparameters_dict.keys():\n",
    "        n_iters = 50\n",
    "    else:\n",
    "        n_iters = 200\n",
    "    df, optimal_weights= ensemble_classification_weights(model_hyperparameters_dict, model_xcols, weather_power_df, Y_feature, n_iters=n_iters)\n",
    "    display(df)\n",
    "    print('Weights:')\n",
    "    for i, k in enumerate(model_hyperparameters_dict.keys()):\n",
    "        print(f'{k}: {optimal_weights[k]:.3f}')\n",
    "\n",
    "this_model_path = train_model_path + f'{Y_feature}/'\n",
    "os.makedirs(this_model_path, exist_ok=True)\n",
    "\n",
    "save_model_metadata(Y_feature, this_model_path + 'meta.json', model_xcols, model_hyperparameters_dict, optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34155e9b-a149-4efe-a18a-b8652bdb7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
